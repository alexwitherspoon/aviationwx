name: Deploy to Production

on:
  workflow_run:
    # Only trigger on Quality Assurance Tests completion (typically runs last)
    # The check-prerequisites job will verify BOTH workflows have succeeded
    workflows: ["Quality Assurance Tests"]
    types:
      - completed
    branches: [ "main" ]
  workflow_dispatch: {} # Allow manual trigger

# Permissions for deployment
permissions:
  contents: read
  actions: read
  checks: read

jobs:
  check-prerequisites:
    runs-on: ubuntu-latest
    outputs:
      test-success: ${{ steps.check.outputs.test-success }}
      qa-success: ${{ steps.check.outputs.qa-success }}
    steps:
      - name: Wait for and check required workflows status
        id: check
        uses: actions/github-script@v7
        with:
          script: |
            // Only deploy on push events (commits/merges to main), not on pull_request events
            // workflow_run event contains the event that triggered the source workflow
            const triggeringEvent = '${{ github.event.workflow_run && github.event.workflow_run.event || github.event_name }}';
            
            core.info(`Triggering event: ${triggeringEvent}`);
            
            // Skip deployment if triggered by a pull_request event
            if (triggeringEvent === 'pull_request') {
              core.info('⏭️  Skipping deployment - triggered by pull_request event (only deploy on push/merge to main)');
              core.setOutput('test-success', 'false');
              core.setOutput('qa-success', 'false');
              return;
            }
            
            // Verify this is a push event (direct commit or merge to main)
            if (triggeringEvent !== 'push') {
              core.warning(`⚠️  Unexpected event type: ${triggeringEvent}. Only push events trigger deployment.`);
              core.setOutput('test-success', 'false');
              core.setOutput('qa-success', 'false');
              return;
            }
            
            // Get the commit SHA - use workflow_run head_sha if available, otherwise context.sha
            const commitSha = '${{ github.event.workflow_run && github.event.workflow_run.head_sha || github.sha }}';
            
            // Get the triggering workflow run ID if available (from workflow_run event)
            // GitHub Actions expressions can't use empty strings directly, so we check in JavaScript
            const triggeringWorkflowRunIdRaw = '${{ github.event.workflow_run && github.event.workflow_run.id }}';
            const triggeringWorkflowRunId = (triggeringWorkflowRunIdRaw && triggeringWorkflowRunIdRaw !== '') ? triggeringWorkflowRunIdRaw : null;
            
            core.info(`Checking workflow statuses for commit: ${commitSha}`);
            if (triggeringWorkflowRunId) {
              core.info(`Triggered by workflow run ID: ${triggeringWorkflowRunId}`);
            }
            
            const maxWaitTime = 30 * 60 * 1000; // 30 minutes in milliseconds
            const checkInterval = 30 * 1000; // Check every 30 seconds
            const startTime = Date.now();
            
            let testRun = null;
            let qaRun = null;
            let testSuccess = false;
            let qaSuccess = false;
            
            // Use workflow file paths instead of IDs (more reliable)
            const testWorkflowPath = '.github/workflows/test.yml';
            const qaWorkflowPath = '.github/workflows/quality-assurance-tests.yml';
            
            core.info(`Looking for workflows: ${testWorkflowPath} and ${qaWorkflowPath}`);
            
            // Wait for both workflows to complete
            while (Date.now() - startTime < maxWaitTime) {
              // Get workflow runs by workflow file path for more specific filtering
              // This ensures we get runs for the specific workflow, not just by name
              const testRuns = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: testWorkflowPath,
                head_sha: commitSha,
                per_page: 10
              });
              
              const qaRuns = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: qaWorkflowPath,
                head_sha: commitSha,
                per_page: 10
              });
              
              // Find the most recent run for this commit (should be the first one)
              // Filter to ensure it's from a push event (not pull_request) and matches the exact commit SHA
              testRun = testRuns.data.workflow_runs.find(run => 
                run.head_sha === commitSha && 
                (run.event === 'push' || run.event === 'workflow_dispatch')
              );
              
              // If no exact match, try the first run (might be a race condition)
              if (!testRun && testRuns.data.workflow_runs.length > 0) {
                const firstRun = testRuns.data.workflow_runs[0];
                // Only use if it's a push event and matches commit (within reasonable time window)
                if (firstRun.event === 'push' && firstRun.head_sha === commitSha) {
                  testRun = firstRun;
                }
              }
              
              // If we have a triggering workflow run ID, use that to find the exact QA run
              if (triggeringWorkflowRunId) {
                qaRun = qaRuns.data.workflow_runs.find(run => 
                  run.id.toString() === triggeringWorkflowRunId
                );
              }
              
              // If not found by ID, try finding by commit SHA and event type
              if (!qaRun) {
                qaRun = qaRuns.data.workflow_runs.find(run => 
                  run.head_sha === commitSha && 
                  (run.event === 'push' || run.event === 'workflow_dispatch')
                );
              }
              
              // If no exact match, try the first run
              if (!qaRun && qaRuns.data.workflow_runs.length > 0) {
                const firstRun = qaRuns.data.workflow_runs[0];
                // Only use if it's a push event and matches commit (within reasonable time window)
                if (firstRun.event === 'push' && firstRun.head_sha === commitSha) {
                  qaRun = firstRun;
                }
              }
              
              const testStatus = testRun?.status; // queued, in_progress, completed
              const testConclusion = testRun?.conclusion; // success, failure, cancelled, etc.
              const qaStatus = qaRun?.status;
              const qaConclusion = qaRun?.conclusion;
              
              core.info(`Test and Lint: ${testStatus || 'not found'} (${testConclusion || 'pending'}) - Run ID: ${testRun?.id || 'N/A'}`);
              core.info(`Quality Assurance Tests: ${qaStatus || 'not found'} (${qaConclusion || 'pending'}) - Run ID: ${qaRun?.id || 'N/A'}`);
              
              // If workflows haven't started yet (queued), wait a bit longer
              if ((testStatus === 'queued' || !testRun) && (qaStatus === 'queued' || !qaRun)) {
                core.info('Workflows are queued or not found yet, waiting...');
                await new Promise(resolve => setTimeout(resolve, checkInterval));
                continue;
              }
              
              // Check if both workflows have completed
              if (testStatus === 'completed' && qaStatus === 'completed') {
                testSuccess = testConclusion === 'success';
                qaSuccess = qaConclusion === 'success';
                break;
              }
              
              // If one has failed, we can stop waiting (but still check both conclusions)
              if (testStatus === 'completed' && testConclusion !== 'success' && testConclusion !== null) {
                testSuccess = false;
                if (qaStatus === 'completed') {
                  qaSuccess = qaConclusion === 'success';
                  break;
                }
              }
              
              if (qaStatus === 'completed' && qaConclusion !== 'success' && qaConclusion !== null) {
                qaSuccess = false;
                if (testStatus === 'completed') {
                  testSuccess = testConclusion === 'success';
                  break;
                }
              }
              
              // Wait before checking again
              core.info('Waiting for both workflows to complete...');
              await new Promise(resolve => setTimeout(resolve, checkInterval));
            }
            
            // Final check - ensure we have both workflows
            if (!testRun || !qaRun) {
              // Get diagnostic info for debugging
              const allTestRuns = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: testWorkflowPath,
                per_page: 5
              });
              
              const allQaRuns = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: qaWorkflowPath,
                per_page: 5
              });
              
              core.error(`❌ Could not find one or both required workflows for commit ${commitSha}`);
              core.error(`Recent Test and Lint runs: ${allTestRuns.data.workflow_runs.map(r => `${r.head_sha.substring(0, 7)} (${r.status})`).join(', ')}`);
              core.error(`Recent Quality Assurance Tests runs: ${allQaRuns.data.workflow_runs.map(r => `${r.head_sha.substring(0, 7)} (${r.status})`).join(', ')}`);
              core.error(`Looking for commit: ${commitSha}`);
              
              if (!testRun) {
                core.error(`Test and Lint: No run found for commit ${commitSha}`);
              }
              if (!qaRun) {
                core.error(`Quality Assurance Tests: No run found for commit ${commitSha}`);
              }
              
              core.setFailed('❌ Could not find one or both required workflows for this commit');
              return;
            }
            
            if (testRun.status !== 'completed' || qaRun.status !== 'completed') {
              core.setFailed(`❌ One or both workflows are still running after wait period:
                - Test and Lint: ${testRun.status} (${testRun.conclusion || 'pending'})
                - Quality Assurance Tests: ${qaRun.status} (${qaRun.conclusion || 'pending'})`);
              return;
            }
            
            core.setOutput('test-success', testSuccess ? 'true' : 'false');
            core.setOutput('qa-success', qaSuccess ? 'true' : 'false');
            
            core.info(`Test and Lint: ${testRun.conclusion || 'unknown'} (ID: ${testRun.id})`);
            core.info(`Quality Assurance Tests: ${qaRun.conclusion || 'unknown'} (ID: ${qaRun.id})`);
            
            if (!testSuccess) {
              core.error(`❌ Test and Lint workflow did not succeed for commit ${commitSha}`);
            }
            if (!qaSuccess) {
              core.error(`❌ Quality Assurance Tests workflow did not succeed for commit ${commitSha}`);
            }
            
            if (testSuccess && qaSuccess) {
              core.info('✅ Both required workflows succeeded - deployment will proceed');
            } else {
              core.setFailed('❌ Not all required workflows succeeded. Deployment blocked.');
            }

  deploy:
    runs-on: ubuntu-latest
    needs: check-prerequisites
    # Only deploy if both workflows succeeded (or manual dispatch which bypasses checks)
    if: |
      (needs.check-prerequisites.outputs.test-success == 'true' && 
       needs.check-prerequisites.outputs.qa-success == 'true') || 
      github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # When triggered by workflow_run, checkout the commit from that workflow
          # Otherwise use the commit SHA from the prerequisites check
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}
          fetch-depth: 0

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: |
            ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add host to known_hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H ${{ secrets.HOST }} >> ~/.ssh/known_hosts

      - name: Update cache version for cache busting
        run: |
          # Generate a unique version based on commit SHA and timestamp
          DEPLOY_VERSION="$(git rev-parse --short HEAD)-$(date +%s)"
          echo "Updating cache version to: ${DEPLOY_VERSION}"
          
          # Update the cache version in public/js/service-worker.js
          # The script handles missing files and verification
          bash scripts/update-cache-version.sh "${DEPLOY_VERSION}"
          
          # Note: We don't commit service-worker.js changes during deployment
          # The updated file will be synced to the server via rsync
          # This avoids creating unnecessary commits and deployment loops
          echo "✓ Cache version updated (will be synced to server)"

      - name: Sync repository to server
        run: |
          rsync -az --delete --exclude '.git' --exclude 'cache' ./ ${{ secrets.USER }}@${{ secrets.HOST }}:~/aviationwx/

      - name: Ensure cache directory exists
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          # Create cache directory in /tmp (ephemeral, cleared on reboot)
          # No sudo needed - /tmp is world-writable by default
          mkdir -p /tmp/aviationwx-cache/webcams
          # Ensure directory is writable (should already be, but be explicit)
          chmod -R 777 /tmp/aviationwx-cache || true
          echo "✓ Cache directory created at /tmp/aviationwx-cache"
          EOF

      - name: Note cache location
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          # Cache is now in /tmp/aviationwx-cache (ephemeral, cleared on reboot)
          # Daily tracking files (peak_gusts.json, temp_extremes.json) will be recreated
          # if missing. Cache is ephemeral by design - useful for resetting state if needed.
          echo "ℹ️  Cache directory: /tmp/aviationwx-cache (ephemeral, cleared on reboot)"
          echo "ℹ️  Application will automatically recreate cache files if missing"
          EOF

      - name: Ensure SSL certificates are in place
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          cd ~/aviationwx
          # Verify we're running as the correct user
          CURRENT_USER=$(whoami)
          echo "Running as user: $CURRENT_USER"
          
          # Create SSL directory if it doesn't exist
          mkdir -p ssl
          
          # Copy SSL certificates from Let's Encrypt if they exist
          # This ensures certificates are available for Nginx container
          # All operations run as aviationwx user, using sudo for protected operations
          # Use sudo test to check if files exist (directory permissions are root-only)
          if sudo test -f /etc/letsencrypt/live/aviationwx.org/fullchain.pem && sudo test -f /etc/letsencrypt/live/aviationwx.org/privkey.pem; then
            echo "Copying SSL certificates from Let's Encrypt..."
            # Copy certificates (requires sudo to read from /etc/letsencrypt/)
            if sudo cp /etc/letsencrypt/live/aviationwx.org/fullchain.pem ssl/; then
              if sudo cp /etc/letsencrypt/live/aviationwx.org/privkey.pem ssl/; then
                # Set correct ownership and permissions
                sudo chown -R $CURRENT_USER:$CURRENT_USER ssl/
                sudo chmod 644 ssl/fullchain.pem
                sudo chmod 600 ssl/privkey.pem
                echo "✓ SSL certificates copied successfully"
              else
                echo "⚠️  Failed to copy privkey.pem"
                exit 1
              fi
            else
              echo "⚠️  Failed to copy fullchain.pem"
              exit 1
            fi
          elif [ -f ssl/fullchain.pem ] && [ -f ssl/privkey.pem ]; then
            echo "✓ SSL certificates already exist in ~/aviationwx/ssl/"
            # Verify permissions are correct
            sudo chown -R $CURRENT_USER:$CURRENT_USER ssl/ || true
            sudo chmod 644 ssl/fullchain.pem || true
            sudo chmod 600 ssl/privkey.pem || true
          else
            echo "⚠️  SSL certificates not found in /etc/letsencrypt/live/aviationwx.org/ or ~/aviationwx/ssl/"
            echo ""
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            echo "SSL CERTIFICATES MISSING"
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            echo ""
            echo "Nginx container will fail to start without SSL certificates."
            echo "You need to generate certificates with Certbot first."
            echo ""
            
            # Check if Certbot is installed
            if command -v certbot >/dev/null 2>&1; then
              echo "✓ Certbot is installed"
              echo ""
              echo "To generate wildcard certificates (DNS-01 challenge):"
              echo ""
              echo "  1. Install Cloudflare DNS plugin:"
              echo "     sudo apt install certbot python3-certbot-dns-cloudflare -y"
              echo ""
              echo "  2. Create Cloudflare API token (scoped to zone):"
              echo "     - Permissions: Zone → DNS → Edit; Zone → Zone → Read"
              echo "     - Resources: Include → Specific zone → aviationwx.org"
              echo ""
              echo "  3. Store token:"
              echo "     mkdir -p ~/.secrets"
              echo "     printf 'dns_cloudflare_api_token = %s\\n' 'YOUR_TOKEN' > ~/.secrets/cloudflare.ini"
              echo "     chmod 600 ~/.secrets/cloudflare.ini"
              echo ""
              echo "  4. Generate certificates:"
              echo "     sudo certbot certonly \\"
              echo "       --dns-cloudflare \\"
              echo "       --dns-cloudflare-credentials ~/.secrets/cloudflare.ini \\"
              echo "       -d aviationwx.org -d '*.aviationwx.org' \\"
              echo "       --non-interactive --agree-tos -m your@email.com"
              echo ""
              echo "  5. Copy certificates:"
              echo "     sudo cp /etc/letsencrypt/live/aviationwx.org/fullchain.pem ~/aviationwx/ssl/"
              echo "     sudo cp /etc/letsencrypt/live/aviationwx.org/privkey.pem ~/aviationwx/ssl/"
              echo "     sudo chown -R $CURRENT_USER:$CURRENT_USER ~/aviationwx/ssl"
              echo "     sudo chmod 644 ~/aviationwx/ssl/fullchain.pem"
              echo "     sudo chmod 600 ~/aviationwx/ssl/privkey.pem"
            else
              echo "⚠️  Certbot is not installed"
              echo ""
              echo "To install Certbot and generate certificates:"
              echo ""
              echo "  1. Install Certbot with Cloudflare DNS plugin:"
              echo "     sudo apt update && sudo apt install -y certbot python3-certbot-dns-cloudflare"
              echo ""
              echo "  2. Follow steps 2-5 above (create Cloudflare token, generate certs, copy them)"
            fi
            
            echo ""
            echo "After certificates are in place, redeploy to continue."
            echo ""
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            echo ""
            # Fail the deployment since Nginx won't start without certificates
            exit 1
          fi
          EOF

      - name: Deploy via Docker Compose
        run: |
          # Get commit SHA from GitHub Actions context (7 characters to match GitHub's short SHA display)
          # Note: .git directory is excluded during rsync, so we can't get SHA from server's git repo
          GIT_SHA="${{ github.event.workflow_run && github.event.workflow_run.head_sha || github.sha }}"
          GIT_SHA="${GIT_SHA:0:7}"
          echo "Deploying with GIT_SHA: ${GIT_SHA}"
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << EOF
          set -euo pipefail
          cd ~/aviationwx
          # Set GIT_SHA as environment variable for docker compose
          export GIT_SHA="$GIT_SHA"
          docker compose -f docker/docker-compose.prod.yml up -d --build
          docker system prune -f
          EOF

      - name: Verify Docker logging configuration
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          cd ~/aviationwx
          # Logging is now handled by Docker (stdout/stderr)
          # Docker automatically captures logs and handles rotation
          # No host-side log directory setup needed
          echo "✓ Docker logging configured (no host setup required)"
          EOF

      - name: Purge browser and service worker caches on server
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          cd ~/aviationwx
          # Force service worker update by updating public/js/service-worker.js timestamp
          # This ensures clients will download new version
          touch public/js/service-worker.js || true
          echo "✓ Updated service worker file timestamp to force cache bust"
          
          # If using Nginx proxy_cache, we would purge here
          # Currently not using proxy_cache, but keeping this for future reference
          # docker exec nginx nginx -s reload || true
          EOF

      - name: Restart Nginx container to pick up config changes
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          cd ~/aviationwx
          # Restart Nginx container to ensure it picks up new nginx.conf
          # This is safer than reload since config file is mounted as volume
          docker compose -f docker/docker-compose.prod.yml restart nginx || docker compose -f docker/docker-compose.prod.yml up -d nginx
          # Verify Nginx container is running and config is valid
          sleep 2
          if docker compose -f docker/docker-compose.prod.yml exec -T nginx nginx -t 2>&1 | grep -q "syntax is ok\|test is successful"; then
            echo "✓ Nginx configuration is valid"
          else
            echo "⚠ Nginx config test failed, but container is running"
          fi
          EOF
      
      - name: Post-deployment health check
        run: |
          ssh ${{ secrets.USER }}@${{ secrets.HOST }} << 'EOF'
          set -euo pipefail
          cd ~/aviationwx
          
          echo "Running post-deployment health checks..."
          
          # Wait for containers to be ready (give them time to start)
          echo "Waiting for containers to start..."
          sleep 8
          
          # Check if containers are running (check both services explicitly)
          CONTAINER_STATUS=$(docker compose -f docker/docker-compose.prod.yml ps --format json 2>/dev/null || docker compose -f docker/docker-compose.prod.yml ps)
          
          # Count running containers (both web and nginx should be up)
          RUNNING_COUNT=$(docker compose -f docker/docker-compose.prod.yml ps --status running --format json 2>/dev/null | grep -c '"State":"running"' || docker compose -f docker/docker-compose.prod.yml ps | grep -c "Up" || echo "0")
          
          # Check that we have at least the web container (nginx is optional but should be running too)
          if [ "$RUNNING_COUNT" -lt "1" ]; then
            echo "❌ Containers are not running"
            echo "Container status:"
            docker compose -f docker/docker-compose.prod.yml ps
            echo ""
            echo "Recent logs:"
            docker compose -f docker/docker-compose.prod.yml logs --tail=30
            exit 1
          fi
          
          echo "✓ Containers are running (${RUNNING_COUNT} container(s) up)"
          
          # Wait for Apache to be fully ready
          echo "Waiting for services to be ready..."
          sleep 10
          
          # Check if web container is responding (from inside container via exec)
          # This is more reliable than checking from host since Apache might have Host header issues
          echo "Testing web container from inside..."
          if ! docker compose -f docker/docker-compose.prod.yml exec -T web curl -f -s --max-time 5 http://localhost/ > /dev/null 2>&1; then
            echo "❌ Web container is not responding (internal check failed)"
            echo "Checking container logs..."
            docker compose -f docker/docker-compose.prod.yml logs web | tail -50
            echo "Checking container status..."
            docker compose -f docker/docker-compose.prod.yml ps
            exit 1
          fi
          
          echo "✓ Web container is responding (internal check passed)"
          
          # Also check from host port (this might fail if Apache has Host header restrictions)
          APP_PORT=${APP_PORT:-8080}
          echo "Testing web container from host on port ${APP_PORT}..."
          if curl -f -s --max-time 5 http://127.0.0.1:${APP_PORT}/ > /dev/null 2>&1; then
            echo "✓ Web container is also responding from host on port ${APP_PORT}"
          else
            echo "⚠️  Web container not accessible from host (but internal check passed - this may be expected)"
            echo "This is OK if Nginx reverse proxy is handling external requests"
          fi
          
          # Check if diagnostics page loads (optional check)
          if ! curl -f -s --max-time 5 http://127.0.0.1:${APP_PORT}/diagnostics.php > /dev/null 2>&1; then
            echo "⚠️  Diagnostics page not accessible (may be expected)"
          else
            echo "✓ Diagnostics page accessible"
          fi
          
          # Check if config-utils.php exists
          if ! docker compose -f docker/docker-compose.prod.yml exec -T web test -f /var/www/html/lib/config.php; then
            echo "❌ config-utils.php not found in container"
            exit 1
          fi
          
          echo "✓ config-utils.php present"
          
          # Check if rate-limit.php exists
          if ! docker compose -f docker/docker-compose.prod.yml exec -T web test -f /var/www/html/lib/rate-limit.php; then
            echo "❌ rate-limit.php not found in container"
            exit 1
          fi
          
          echo "✓ rate-limit.php present"
          
          # Check APCu extension
          if ! docker compose -f docker/docker-compose.prod.yml exec -T web php -m | grep -q apcu; then
            echo "⚠️  APCu extension not loaded (rate limiting will be disabled)"
          else
            echo "✓ APCu extension loaded"
          fi
          
          echo "✅ All health checks passed"
          
          # Test webcam endpoints (smoke test)
          echo "Testing webcam endpoints..."
          # Test JPG endpoint for sample airport (assuming kspb exists)
          if curl -f -s --max-time 10 "http://127.0.0.1:${APP_PORT}/webcam.php?id=kspb&cam=0&fmt=jpg" > /tmp/webcam_test.jpg 2>/dev/null; then
            SIZE=$(stat -f%z /tmp/webcam_test.jpg 2>/dev/null || stat -c%s /tmp/webcam_test.jpg 2>/dev/null || echo "0")
            CTYPE=$(curl -sI "http://127.0.0.1:${APP_PORT}/webcam.php?id=kspb&cam=0&fmt=jpg" 2>/dev/null | grep -i 'content-type' | cut -d' ' -f2 | tr -d '\r' || echo "")
            if [ "$SIZE" -gt "0" ] && echo "$CTYPE" | grep -qi "image/jpeg"; then
              echo "✓ Webcam JPG endpoint working (size: ${SIZE} bytes, type: ${CTYPE})"
              rm -f /tmp/webcam_test.jpg
            else
              echo "⚠️  Webcam JPG endpoint returned invalid response (size: ${SIZE}, type: ${CTYPE})"
            fi
          else
            echo "⚠️  Webcam JPG endpoint not accessible (may be expected if no webcams configured)"
          fi
          
          # Test WEBP endpoint
          if curl -f -s --max-time 10 "http://127.0.0.1:${APP_PORT}/webcam.php?id=kspb&cam=0&fmt=webp" > /tmp/webcam_test.webp 2>/dev/null; then
            SIZE=$(stat -f%z /tmp/webcam_test.webp 2>/dev/null || stat -c%s /tmp/webcam_test.webp 2>/dev/null || echo "0")
            CTYPE=$(curl -sI "http://127.0.0.1:${APP_PORT}/webcam.php?id=kspb&cam=0&fmt=webp" 2>/dev/null | grep -i 'content-type' | cut -d' ' -f2 | tr -d '\r' || echo "")
            if [ "$SIZE" -gt "0" ] && echo "$CTYPE" | grep -qi "image/webp"; then
              echo "✓ Webcam WEBP endpoint working (size: ${SIZE} bytes, type: ${CTYPE})"
              rm -f /tmp/webcam_test.webp
            else
              echo "⚠️  Webcam WEBP endpoint returned invalid response (size: ${SIZE}, type: ${CTYPE})"
            fi
          else
            echo "ℹ️  Webcam WEBP endpoint not accessible (may be expected if WEBP not generated yet)"
          fi
          
          EOF

